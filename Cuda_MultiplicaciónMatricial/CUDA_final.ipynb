{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix multiplication"
      ],
      "metadata": {
        "id": "k5nSPNDF9XMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73CrIBOgaoNq",
        "outputId": "b64d94bd-b939-4e86-ff4a-e7d47fd852bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src"
      ],
      "metadata": {
        "id": "fGhM9JyQGMQP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt2LKCynGWId",
        "outputId": "4329dfb4-a24b-455c-b416-ddd401311824"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 0MatMul"
      ],
      "metadata": {
        "id": "wUNuc9XlasYr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/src/0MatMul/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nG1Kjd0awhP",
        "outputId": "445e4d47-d82b-4477-d4f6-ac634af77a44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src/0MatMul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mulmatrix.cu\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include \"math.h\"\n",
        "#include \"time.h\"\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <iomanip>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "void print_matrices(float* matrix, const char* file_Name, int x_dim, int y_dim, int dim)\n",
        "{\n",
        "    std::ofstream outFile;\n",
        "    outFile.open (file_Name);\n",
        "\n",
        "    outFile << std::fixed;\n",
        "    outFile << std::setprecision(2);\n",
        "\n",
        "    for (int i = 0; i < x_dim; i++) {\n",
        "\n",
        "        for (int j = 0; j < y_dim; j++) {\n",
        "            outFile << matrix[i * dim + j] << \" \";\n",
        "        }\n",
        "        outFile << std::endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU matrix multiplication code\n",
        "__host__ void cpu_matrix_mult(float *h_a, float *h_b, float *h_result, int m) {\n",
        "    for (int i = 0; i < m; ++i)\n",
        "    {\n",
        "        for (int j = 0; j < m; ++j)\n",
        "        {\n",
        "            float tmp = 0.0;\n",
        "            for (int h = 0; h < m; ++h)\n",
        "            {\n",
        "                tmp += h_a[i * m + h] * h_b[h * m + j];\n",
        "            }\n",
        "            h_result[i * m + j] = tmp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__host__ int fill(float **Lmatrix, float **Rmatrix, int LdimX, int LdimY, int RdimX, int RdimY) {\n",
        "\n",
        "    int sqr_dim_X, sqr_dim_Y, size;\n",
        "\n",
        "    sqr_dim_X = RdimX;\n",
        "    if (LdimX > RdimX) {\n",
        "        sqr_dim_X = LdimX;\n",
        "    }\n",
        "\n",
        "    sqr_dim_Y = RdimY;\n",
        "    if (LdimY > RdimY) {\n",
        "        sqr_dim_Y = LdimY;\n",
        "    }\n",
        "\n",
        "    size = sqr_dim_Y;\n",
        "    if (sqr_dim_X > sqr_dim_Y) {\n",
        "        size = sqr_dim_X;\n",
        "    }\n",
        "\n",
        "    int temp = size / BLOCK_SIZE + (size % BLOCK_SIZE == 0 ? 0 : 1);\n",
        "    size = temp * BLOCK_SIZE;\n",
        "\n",
        "    size_t pt_size = size * size * sizeof(float);\n",
        "\n",
        "    *Lmatrix = (float *) malloc(pt_size);\n",
        "    *Rmatrix = (float *) malloc(pt_size);\n",
        "\n",
        "    memset(*Lmatrix, 0, pt_size);\n",
        "    memset(*Rmatrix, 0, pt_size);\n",
        "\n",
        "    for (int i = 0; i < LdimX; i++) {\n",
        "        for (int j = 0; j < LdimY; j++) {\n",
        "            int dummy = size * i + j;\n",
        "            (*Lmatrix)[dummy] = sinf(dummy);\n",
        "        }\n",
        "    }\n",
        "    for (int i = 0; i < RdimX; i++) {\n",
        "        for (int j = 0; j < RdimY; j++) {\n",
        "            int dummy = size * i + j;\n",
        "            (*Rmatrix)[dummy] = cosf(dummy);\n",
        "        }\n",
        "    }\n",
        "    return size;\n",
        "}\n",
        "\n",
        "__global__ void multiply(float *left, float *right, float *res, int dim) {\n",
        "\n",
        "    int i,j;\n",
        "    float temp = 0;\n",
        "\n",
        "    __shared__ float Left_shared_t [BLOCK_SIZE][BLOCK_SIZE];\n",
        "    __shared__ float Right_shared_t[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "    // Row i of matrix left\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "    for (int tileNUM = 0; tileNUM < gridDim.x; tileNUM++) {\n",
        "\n",
        "        // Column j of matrix left\n",
        "        j = tileNUM * BLOCK_SIZE + threadIdx.x;\n",
        "        i = tileNUM * BLOCK_SIZE + threadIdx.y;\n",
        "        // Load left[i][j] to shared mem\n",
        "\n",
        "        Left_shared_t[threadIdx.y][threadIdx.x] = left[row * dim + j];// Coalesced access\n",
        "        \n",
        "        // Load right[i][j] to shared mem\n",
        "        Right_shared_t[threadIdx.y][threadIdx.x] = right[i * dim + col]; // Coalesced access\n",
        "        __syncthreads();\n",
        "\n",
        "        // Accumulate one tile of res from tiles of left and right in shared mem\n",
        "        for (int k = 0; k < BLOCK_SIZE; k++) {\n",
        "\n",
        "            temp += Left_shared_t[threadIdx.y][k] * Right_shared_t[k][threadIdx.x]; //no shared memory bank conflict\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // Store accumulated value to res\n",
        "    res[row * dim + col] = temp;\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    int Left_matrix_x, Left_matrix_y, Right_matrix_x, Right_matrix_y;\n",
        "\n",
        "    float *Left_Vector_h, *Right_Vector_h, *Left_Vector_d, *Right_Vector_d, *Res_h, *Res_d, *CPU;  // Pointer to host & device arrays\n",
        "\n",
        "    printf(\"Enter m n n k :\\n\");\n",
        "\n",
        "    scanf(\"%d %d %d %d\",&Left_matrix_x,&Left_matrix_y,&Right_matrix_x,&Right_matrix_y); // input matrix dimensions are taken\n",
        "\n",
        "    int dim = fill(&Left_Vector_h, &Right_Vector_h, Left_matrix_x, Left_matrix_y, Right_matrix_x, Right_matrix_y); //fills the matrices with random values\n",
        "\n",
        "    print_matrices(Left_Vector_h,\"Input_LHS\",Left_matrix_x,Left_matrix_y,dim);\n",
        "    print_matrices(Right_Vector_h,\"Input_RHS\",Right_matrix_x,Right_matrix_y,dim);\n",
        "\n",
        "    size_t vector_size;\n",
        "    vector_size = dim*dim * sizeof(float);\n",
        "\n",
        "    Res_h = (float *) malloc(vector_size); // Allocate array on host for result\n",
        "    CPU = (float *) malloc(vector_size);// Allocate array on host for CPU_matrix_multiplication result\n",
        "\n",
        "    cudaMalloc((void **) &Left_Vector_d, vector_size);     // Allocate array on device for LHS operand\n",
        "    cudaMalloc((void **) &Right_Vector_d, vector_size);   // Allocate array on device for RHS operand but this is vector 1xN\n",
        "    cudaMalloc((void **) &Res_d, vector_size);     // Allocate array on device for result\n",
        "\n",
        "    cudaMemcpy(Left_Vector_d, Left_Vector_h, vector_size, cudaMemcpyHostToDevice);      // copy values to device\n",
        "    cudaMemcpy(Right_Vector_d, Right_Vector_h, vector_size, cudaMemcpyHostToDevice);   // copy values to device\n",
        "\n",
        "    //Block dimension is directly from block_size\n",
        "    dim3 Block_dim(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    //Grid dimension is found by dividing matrix dimension to block_size\n",
        "    dim3 Grid_dim(dim / BLOCK_SIZE, dim / BLOCK_SIZE);\n",
        "\n",
        "    //commented out the functions which helps to calculate time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start,0);\n",
        "\n",
        "    //kernel call\n",
        "    multiply << < Grid_dim, Block_dim >> > (Left_Vector_d, Right_Vector_d, Res_d, dim);\n",
        "\n",
        "    //commented out the functions which helps to calculate time\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float et;\n",
        "    cudaEventElapsedTime(&et, start, stop);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    // Retrieve result from device and store it in host array\n",
        "    cudaMemcpy(Res_h, Res_d, vector_size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    clock_t begin = clock();\n",
        "\n",
        "    cpu_matrix_mult(Left_Vector_h,Right_Vector_h,CPU,dim); //matrix multiplication on cpu\n",
        "\n",
        "    clock_t end = clock();\n",
        "    double time_spent = (double)1000*(end - begin) / CLOCKS_PER_SEC;\n",
        "\n",
        "    //commented out the functions which helps to calculate time\n",
        "    printf(\"GPU time= %f ms\\n\", et);\n",
        "\n",
        "    printf(\"CPU time= %lf ms\\n\", time_spent);\n",
        "\n",
        "    //Prints the results\n",
        "    print_matrices(Res_h,\"GPU_out\",Left_matrix_x,Right_matrix_y,dim);\n",
        "    print_matrices(CPU,\"CPU_out\",Left_matrix_x,Right_matrix_y,dim);\n",
        "\n",
        "    bool eqaul = true;\n",
        "    for (int i=0;i< Left_matrix_x && eqaul;i++){\n",
        "        for (int j = 0; j < Right_matrix_y && eqaul; j++) {\n",
        "            if (abs(Res_h[i*dim+j]-CPU[i*dim+j]) > 0.001)\n",
        "            {\n",
        "                eqaul = false;\n",
        "                printf(\"NOT EQUAL\\n\");\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    if (eqaul)\n",
        "    {\n",
        "        std::cout<<\"Results are equal!\"<<std::endl;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        std::cout<<\"Results are NOT equal!\"<<std::endl;\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    free(Left_Vector_h);\n",
        "    free(Right_Vector_h);\n",
        "    free(Res_h);\n",
        "    free(CPU);\n",
        "    cudaFree(Left_Vector_d);\n",
        "    cudaFree(Right_Vector_d);\n",
        "    cudaFree(Res_d);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAuC2-MoEY8X",
        "outputId": "87163469-9a9c-4000-ae1b-0b7ae2657e2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mulmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMlM7cjrcBuE",
        "outputId": "25581e54-e379-4397-ee8f-aad8f99a0899"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 2.8.12 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- The CUDA compiler identification is NVIDIA 11.2.152\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Configuring done\n",
            "\u001b[33mCMake Warning (dev) in CMakeLists.txt:\n",
            "  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,\n",
            "  empty CUDA_ARCHITECTURES not allowed.  Run \"cmake --help-policy CMP0104\"\n",
            "  for policy details.  Use the cmake_policy command to set the policy and\n",
            "  suppress this warning.\n",
            "\n",
            "  CUDA_ARCHITECTURES is empty for target \"mulmatrix\".\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "\u001b[33mCMake Warning (dev) in CMakeLists.txt:\n",
            "  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,\n",
            "  empty CUDA_ARCHITECTURES not allowed.  Run \"cmake --help-policy CMP0104\"\n",
            "  for policy details.  Use the cmake_policy command to set the policy and\n",
            "  suppress this warning.\n",
            "\n",
            "  CUDA_ARCHITECTURES is empty for target \"mulmatrix\".\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/src/0MatMul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzA3RbT3cD7c",
        "outputId": "eebd649d-b03b-40f3-b2fb-36d31966cacc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 50%] \u001b[32mBuilding CUDA object CMakeFiles/mulmatrix.dir/mulmatrix.cu.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CUDA executable mulmatrix\u001b[0m\n",
            "[100%] Built target mulmatrix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./mulmatrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQuyzmP0cL4j",
        "outputId": "d3792048-ffe6-4b2b-9537-c69311300ea2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter m n n k :\n",
            "1024 1024 1024 1024\n",
            "GPU time= 5.800832 ms\n",
            "CPU time= 7162.116000 ms\n",
            "Results are equal!\n",
            "\n",
            "real\t0m28.770s\n",
            "user\t0m8.549s\n",
            "sys\t0m0.802s\n"
          ]
        }
      ]
    }
  ]
}